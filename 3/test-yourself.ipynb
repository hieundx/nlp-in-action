{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Difference between `CountVectorizer.transform()` and `collections.Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9\n",
      "Counter({'The': 1, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'the': 1, 'lazy': 1, 'dog': 1})\n",
      "[[0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "sentence = 'The quick brown fox jumps over the lazy dog'\n",
    "tokens = sentence.split()\n",
    "print('Vocabulary size:', len(set(tokens)))\n",
    "\n",
    "counts = Counter(tokens)\n",
    "counts_vectorized = count_vectorizer.fit_transform(tokens)\n",
    "\n",
    "print(counts)\n",
    "print(counts_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer` returns a *vectorized* bag-of-words of the sentence. `collections.Counter` returns a dictionary where each item is a mapping from a token to its count in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Can you use TFIDFVectorizer on a large corpus (more than 1M documents) with a huge vocabulary (more than 1M tokens)? What problems do you expect to encounter?\n",
    "\n",
    "The short answer is no. Because `TFIDFVectorizer` creates a sparse vector. On a large corpus with a hugh library, this results in a very large matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Think of an example of corpus or task where term frequency (TF) will perform better than TF-IDF.\n",
    "\n",
    "Technical manuals will benefit from TF because the relevant terms will likely be contained within one document. For example, if we have a PC manual of 4 documents about: CPU, GPU, RAM, peripherals. The CPU documents will contain the terms such as \"transistor\", \"register\", \"x86\", \"FLOPS\", etc. These terms are not as common or may even be absent in other documents. So using TF to search for documents about CPU will perform better than TF-IDF because we don't have to do extra processing for IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    {\n",
    "        \"title\": \"CPU\",\n",
    "        \"content\": \"\"\"\n",
    "            The Central Processing Unit (CPU) is the brain of your computer. Our latest model features:\n",
    "            - Advanced x86-64 Intel/AMD architecture\n",
    "            - 8 physical cores with 16 threads via hyper-threading\n",
    "            - 3.5 GHz base clock, up to 5.0 GHz with Turbo Boost\n",
    "            - 16 MB L3 cache, 512 KB L2 cache per core\n",
    "            - Support for DDR4-3200 memory\n",
    "            - 14nm manufacturing process with over 10 billion transistors\n",
    "            - Integrated heat spreader for optimal thermal management\n",
    "            - Advanced vector extensions (AVX) for enhanced FLOPS performance\n",
    "            - Hardware-level virtualization support\n",
    "            - Secure enclave for encrypted operations\n",
    "            - Compatible with LGA 1200 socket motherboards\n",
    "            The CPU's arithmetic logic unit (ALU) performs calculations, while the floating-point unit (FPU) handles decimal computations. The control unit manages instruction flow through the pipeline, optimizing IPC (Instructions Per Clock) for maximum efficiency.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"GPU\",\n",
    "        \"content\": \"\"\"\n",
    "            The Graphics Processing Unit (GPU) is responsible for rendering images, video, and 3D graphics. Key features include:\n",
    "            - NVIDIA Ampere architecture\n",
    "            - 10 GB GDDR6X memory\n",
    "            - 8704 CUDA cores for parallel processing\n",
    "            - 1.71 GHz boost clock\n",
    "            - Real-time ray tracing capabilities\n",
    "            - 8K HDR gaming support\n",
    "            - PCIe 4.0 interface for high-speed data transfer\n",
    "            - Three DisplayPort 1.4a and one HDMI 2.1 output\n",
    "            - NVIDIA DLSS (Deep Learning Super Sampling) technology\n",
    "            - GPU Boost 3.0 for intelligent clock speed management\n",
    "            - VR Ready for immersive gaming experiences\n",
    "            The GPU's shader units handle complex lighting and texture calculations, while its raster operations pipeline (ROP) manages final pixel output to your display.\n",
    "        \"\"\",\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"title\": \"RAM\",\n",
    "        \"content\": \"\"\"\n",
    "            Random Access Memory (RAM) provides fast, temporary data storage for active programs and processes. Our latest DDR4 modules offer:\n",
    "            - 3200 MHz clock speed\n",
    "            - CL16-18-18-38 timings for responsive performance\n",
    "            - 32 GB capacity (2 x 16 GB dual-channel kit)\n",
    "            - XMP 2.0 support for easy overclocking\n",
    "            - Aluminum heat spreaders for effective cooling\n",
    "            - 1.35V operating voltage\n",
    "            - Unbuffered, non-ECC design for consumer systems\n",
    "            - Lifetime warranty\n",
    "            RAM communicates with the CPU via the memory controller, utilizing multi-channel architecture to maximize bandwidth. The JEDEC standard ensures compatibility across different systems.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Peripherals\",\n",
    "        \"content\": \"\"\"\n",
    "            Enhance your computing experience with our range of peripherals:\n",
    "            1. Mechanical Keyboard\n",
    "            - Cherry MX Blue switches for tactile feedback\n",
    "            - Full N-key rollover\n",
    "            - Customizable RGB backlighting\n",
    "            - Programmable macro keys\n",
    "            - Detachable USB-C cable\n",
    "            2. Optical Mouse\n",
    "            - 16,000 DPI optical sensor\n",
    "            - 1000 Hz polling rate\n",
    "            - 8 programmable buttons\n",
    "            - Adjustable weight system\n",
    "            - Ergonomic right-handed design\n",
    "            3. 4K Monitor\n",
    "            - 27-inch IPS panel\n",
    "            - 3840 x 2160 resolution\n",
    "            - 144 Hz refresh rate\n",
    "            - 1 ms GTG response time\n",
    "            - HDR400 certified\n",
    "            - FreeSync and G-Sync compatible\n",
    "            4. Webcam\n",
    "            - 1080p/60fps video capture\n",
    "            - Dual noise-cancelling microphones\n",
    "            - Auto-focus and light correction\n",
    "            - Privacy shutter\n",
    "            - USB 3.0 connectivity\n",
    "            These peripherals connect to your system via USB ports, utilizing plug-and-play technology for easy setup. Customization software allows for personalized configurations to suit your needs.\n",
    "        \"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_text = [doc['content'] for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply_tfidf(question):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer.fit(corpus_text)\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(corpus_text)\n",
    "        \n",
    "    question_vectorized = tfidf_vectorizer.transform([question])\n",
    "    similarity = tfidf_matrix.dot(question_vectorized.T)\n",
    "    most_similar_idx = similarity.argmax()\n",
    "    \n",
    "    print('Question: ', question)\n",
    "    print('Most relevant document: ', corpus[most_similar_idx]['title'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  x86-64 architecture\n",
      "Most relevant document:  CPU\n",
      "\n",
      "Question:  NVIDIA Ampere architecture\n",
      "Most relevant document:  GPU\n",
      "\n",
      "Question:  DDR4 memory\n",
      "Most relevant document:  RAM\n",
      "\n",
      "Question:  mechanical keyboard\n",
      "Most relevant document:  Peripherals\n",
      "\n",
      "Question:  1080p 60fps video capture\n",
      "Most relevant document:  Peripherals\n",
      "\n",
      "Question:  Intel\n",
      "Most relevant document:  CPU\n",
      "\n",
      "Time elapsed: 0.010000228881835938\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def test_search(search_method):\n",
    "    start_time = time.time()\n",
    "    search_method('x86-64 architecture')\n",
    "    search_method('NVIDIA Ampere architecture')\n",
    "    search_method('DDR4 memory')\n",
    "    search_method('mechanical keyboard')\n",
    "    search_method('1080p 60fps video capture')\n",
    "    search_method('Intel')\n",
    "    end_time = time.time()\n",
    "    print('Time elapsed:', end_time - start_time)\n",
    "\n",
    "test_search(reply_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tb_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def compute_tf(doc):\n",
    "    word_counts = Counter(tb_tokenizer.tokenize(doc))\n",
    "    return {\n",
    "        word: count / len(word_counts) for word, count in word_counts.items()\n",
    "    }\n",
    "\n",
    "def search_docs(query):\n",
    "    query_tokens = tb_tokenizer.tokenize(query)\n",
    "    \n",
    "    doc_tfs = [compute_tf(doc) for doc in corpus_text]\n",
    "    \n",
    "    scores = []\n",
    "    for i, doc_tf in enumerate(doc_tfs):\n",
    "        score = sum(doc_tf.get(token, 0) for token in query_tokens)\n",
    "        scores.append((i, score))\n",
    "        \n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def reply_tf(question):\n",
    "    results = search_docs(question)\n",
    "    most_relevant_idx = results[0][0]\n",
    "    \n",
    "    print('Question: ', question)\n",
    "    print('Most relevant document:', corpus[most_relevant_idx]['title'])   \n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  x86-64 architecture\n",
      "Most relevant document: CPU\n",
      "\n",
      "Question:  NVIDIA Ampere architecture\n",
      "Most relevant document: GPU\n",
      "\n",
      "Question:  DDR4 memory\n",
      "Most relevant document: RAM\n",
      "\n",
      "Question:  mechanical keyboard\n",
      "Most relevant document: CPU\n",
      "\n",
      "Question:  1080p 60fps video capture\n",
      "Most relevant document: Peripherals\n",
      "\n",
      "Question:  Intel\n",
      "Most relevant document: CPU\n",
      "\n",
      "Time elapsed: 0.006998300552368164\n"
     ]
    }
   ],
   "source": [
    "test_search(reply_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
